{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54d4d919-9086-4bd0-9533-87ddf6232260",
   "metadata": {},
   "source": [
    "# 16S Model Training and Evaluation\n",
    "\n",
    "**Objective:** To build, train, and evaluate a deep learning classifier for the 16S rRNA gene using the pre-processed data.\n",
    "\n",
    "**Methodology:**\n",
    "1. Load the training/testing data and encoders from disk.\n",
    "2. Define the neural network architecture using TensorFlow/Keras.\n",
    "3. Train the model on the training data, using the GPU if available.\n",
    "4. Evaluate the final model's accuracy on the unseen test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c866ac0-2727-4016-bb94-936338adb111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- TensorFlow Setup ---\n",
      "TensorFlow Version: 2.10.1\n",
      "✅ GPU detected: PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n",
      "--------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from scipy.sparse import load_npz\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "# Set up project path\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.append(str(project_root))\n",
    "\n",
    "# --- Verification Step: Check for GPU ---\n",
    "# This will tell us if TensorFlow can see your GPU.\n",
    "print(\"--- TensorFlow Setup ---\")\n",
    "print(f\"TensorFlow Version: {tf.__version__}\")\n",
    "gpu_devices = tf.config.list_physical_devices('GPU')\n",
    "if gpu_devices:\n",
    "    print(f\"✅ GPU detected: {gpu_devices[0]}\")\n",
    "else:\n",
    "    print(\"⚠️ No GPU detected. TensorFlow will run on CPU.\")\n",
    "print(\"-\" * 26)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b92b03-1dbf-4385-bf3b-44a02129c5bf",
   "metadata": {},
   "source": [
    "### Step 2: Load Pre-processed Data and Encoders\n",
    "\n",
    "We will now load all the artifacts that were saved by our data preparation notebook. This includes the training data, testing data, and the crucial `vectorizer` and `label_encoder` objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "893ba25a-a7c8-4eb5-8eb6-5a8b9546301f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from disk...\n",
      "✅ Data loading complete.\n",
      "\n",
      "--- Loaded Data Shapes ---\n",
      "Shape of X_train: (4744, 13261)\n",
      "Shape of y_train: (4744,)\n",
      "------------------------------\n",
      "Shape of X_test:  (1186, 13261)\n",
      "Shape of y_test:  (1186,)\n",
      "Number of classes (genera): 529\n"
     ]
    }
   ],
   "source": [
    "# --- Define file paths ---\n",
    "PROCESSED_DATA_DIR = project_root / \"data\" / \"processed\"\n",
    "MODELS_DIR = project_root / \"models\"\n",
    "\n",
    "X_TRAIN_PATH = PROCESSED_DATA_DIR / \"X_train_16s.npz\"\n",
    "X_TEST_PATH = PROCESSED_DATA_DIR / \"X_test_16s.npz\"\n",
    "Y_TRAIN_PATH = PROCESSED_DATA_DIR / \"y_train_16s.npy\"\n",
    "Y_TEST_PATH = PROCESSED_DATA_DIR / \"y_test_16s.npy\"\n",
    "\n",
    "VECTORIZER_PATH = MODELS_DIR / \"16s_genus_vectorizer.pkl\"\n",
    "LABEL_ENCODER_PATH = MODELS_DIR / \"16s_genus_label_encoder.pkl\"\n",
    "\n",
    "\n",
    "# --- Load the data and encoders ---\n",
    "print(\"Loading data from disk...\")\n",
    "X_train = load_npz(X_TRAIN_PATH)\n",
    "X_test = load_npz(X_TEST_PATH)\n",
    "y_train = np.load(Y_TRAIN_PATH)\n",
    "y_test = np.load(Y_TEST_PATH)\n",
    "\n",
    "with open(LABEL_ENCODER_PATH, 'rb') as f:\n",
    "    label_encoder = pickle.load(f)\n",
    "\n",
    "# Note: We don't need to load the vectorizer right now, but we will need it for a final script.\n",
    "# The label_encoder is important because it tells us the number of classes.\n",
    "print(\"✅ Data loading complete.\")\n",
    "\n",
    "\n",
    "# --- Verification Step ---\n",
    "print(\"\\n--- Loaded Data Shapes ---\")\n",
    "print(f\"Shape of X_train: {X_train.shape}\")\n",
    "print(f\"Shape of y_train: {y_train.shape}\")\n",
    "print(\"-\" * 30)\n",
    "print(f\"Shape of X_test:  {X_test.shape}\")\n",
    "print(f\"Shape of y_test:  {y_test.shape}\")\n",
    "print(f\"Number of classes (genera): {len(label_encoder.classes_)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc17411d-5027-4163-836f-5207a4660003",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
