{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ec56556-4692-41db-aaba-ff9ef105b73d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project Root: C:\\Users\\jampa\\Music\\atlas\n",
      "\n",
      "--- TensorFlow Setup ---\n",
      "  - TensorFlow Version: 2.10.1\n",
      "  - GPU detected: PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n",
      "--------------------------\n",
      "\n",
      "--- Loading ITS Data ---\n",
      "  - Data loading complete.\n",
      "\n",
      "--- Loaded Data Shapes ---\n",
      "  - Shape of X_train: (6696, 18837)\n",
      "  - Shape of y_train: (6696,)\n",
      "  ------------------------------\n",
      "  - Shape of X_test:  (1674, 18837)\n",
      "  - Shape of y_test:  (1674,)\n",
      "  - Number of classes (genera): 634\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# -----------------------------------------------------------------------------\n",
    "#\n",
    "#                    ATLAS v3: ITS Model Training (Fungi)\n",
    "#\n",
    "# -----------------------------------------------------------------------------\n",
    "#\n",
    "#   OBJECTIVE:\n",
    "#\n",
    "#       To build, train, and evaluate a deep learning classifier for the ITS\n",
    "#       region using the pre-processed data from the UNITE database.\n",
    "#\n",
    "#   METHODOLOGY:\n",
    "#\n",
    "#       1.  Load the ITS-specific training/testing data and encoders from disk.\n",
    "#       2.  Define the standard neural network architecture.\n",
    "#       3.  Train the model on the training data using the GPU.\n",
    "#       4.  Save, reload, and evaluate the final model's accuracy on the\n",
    "#           unseen test set, following our memory-safe workflow.\n",
    "#\n",
    "# -----------------------------------------------------------------------------\n",
    "#\n",
    "\n",
    "# --- Imports ---\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from scipy.sparse import load_npz\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "# --- Setup Project Path ---\n",
    "try:\n",
    "    project_root = Path(__file__).parent.parent\n",
    "except NameError:\n",
    "    project_root = Path.cwd().parent\n",
    "print(f\"Project Root: {project_root}\")\n",
    "\n",
    "\n",
    "# --- 1. Verification Step: Check for GPU ---\n",
    "print(\"\\n--- TensorFlow Setup ---\")\n",
    "print(f\"  - TensorFlow Version: {tf.__version__}\")\n",
    "gpu_devices = tf.config.list_physical_devices('GPU')\n",
    "if gpu_devices:\n",
    "    print(f\"  - GPU detected: {gpu_devices[0]}\")\n",
    "else:\n",
    "    print(\"  - WARNING: No GPU detected. TensorFlow will run on CPU.\")\n",
    "print(\"--------------------------\")\n",
    "\n",
    "\n",
    "# --- 2. Define ITS-specific file paths ---\n",
    "PROCESSED_DATA_DIR = project_root / \"data\" / \"processed\"\n",
    "MODELS_DIR = project_root / \"models\"\n",
    "\n",
    "X_TRAIN_PATH = PROCESSED_DATA_DIR / \"X_train_its.npz\"\n",
    "X_TEST_PATH = PROCESSED_DATA_DIR / \"X_test_its.npz\"\n",
    "Y_TRAIN_PATH = PROCESSED_DATA_DIR / \"y_train_its.npy\"\n",
    "Y_TEST_PATH = PROCESSED_DATA_DIR / \"y_test_its.npy\"\n",
    "\n",
    "LABEL_ENCODER_PATH = MODELS_DIR / \"its_genus_label_encoder.pkl\"\n",
    "\n",
    "\n",
    "# --- 3. Load the data and encoders ---\n",
    "print(\"\\n--- Loading ITS Data ---\")\n",
    "try:\n",
    "    X_train = load_npz(X_TRAIN_PATH)\n",
    "    X_test = load_npz(X_TEST_PATH)\n",
    "    y_train = np.load(Y_TRAIN_PATH)\n",
    "    y_test = np.load(Y_TEST_PATH)\n",
    "\n",
    "    with open(LABEL_ENCODER_PATH, 'rb') as f:\n",
    "        label_encoder = pickle.load(f)\n",
    "    print(\"  - Data loading complete.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"\\n[ERROR] Processed data not found.\")\n",
    "    print(\"        Please run `python src/pipeline_its/01_prepare_data.py` before starting this notebook.\")\n",
    "    # Stop execution if files are missing\n",
    "    raise\n",
    "\n",
    "# --- 4. Verification Step ---\n",
    "print(\"\\n--- Loaded Data Shapes ---\")\n",
    "print(f\"  - Shape of X_train: {X_train.shape}\")\n",
    "print(f\"  - Shape of y_train: {y_train.shape}\")\n",
    "print(\"  ------------------------------\")\n",
    "print(f\"  - Shape of X_test:  {X_test.shape}\")\n",
    "print(f\"  - Shape of y_test:  {y_test.shape}\")\n",
    "print(f\"  - Number of classes (genera): {len(label_encoder.classes_)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "727f935e-92a6-4a74-a0e3-3e01dca98e98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Defining ITS Model Architecture ---\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 2048)              38580224  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 2048)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1024)              2098176   \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 634)               649850    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 41,328,250\n",
      "Trainable params: 41,328,250\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "--- Preparing Data and Starting Training ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jampa\\.conda\\envs\\atlas-v3\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential/dense/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential/dense/embedding_lookup_sparse/Reshape:0\", shape=(None, 2048), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential/dense/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 08/50 | Loss: 1.2294 | Acc: 73.42% [██████████████······] | Val_Loss: 1.8791 | Val_Acc: 64.63% [████████████········]Restoring model weights from the end of the best epoch: 6.\n",
      "Epoch 09/50 | Loss: 1.2158 | Acc: 74.58% [██████████████······] | Val_Loss: 1.9036 | Val_Acc: 64.33% [████████████········]Epoch 9: early stopping\n",
      "\n",
      "\n",
      "--- Training complete. ---\n",
      "\n",
      "Saving trained model to: C:\\Users\\jampa\\Music\\atlas\\models\\its_genus_classifier.keras\n",
      "  - Model saved successfully.\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# -----------------------------------------------------------------------------\n",
    "#\n",
    "#                     STEP 2: DEFINE AND TRAIN THE ITS MODEL\n",
    "#\n",
    "# -----------------------------------------------------------------------------\n",
    "#\n",
    "#   OBJECTIVE:\n",
    "#\n",
    "#       To define the neural network architecture, train it on the prepared\n",
    "#       ITS data, and save the resulting model artifact to disk.\n",
    "#\n",
    "#   WORKFLOW:\n",
    "#\n",
    "#       1.  Define the Keras Sequential model architecture, dynamically\n",
    "#           sizing it to the input features and output classes of the ITS dataset.\n",
    "#       2.  Create a validation set and define callbacks for Early Stopping\n",
    "#           and clean progress reporting.\n",
    "#       3.  Execute the training using `model.fit()`.\n",
    "#       4.  Immediately save the best version of the trained model to disk.\n",
    "#\n",
    "# -----------------------------------------------------------------------------\n",
    "#\n",
    "\n",
    "# --- Imports for this cell ---\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, Callback\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# --- PART 1: Define and Compile Model ---\n",
    "print(\"--- Defining ITS Model Architecture ---\")\n",
    "num_classes = len(label_encoder.classes_)\n",
    "input_shape = X_train.shape[1]\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(2048, activation='relu', input_shape=(input_shape,)),\n",
    "    Dropout(0.5),\n",
    "    Dense(1024, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "\n",
    "# --- PART 2: Prepare Data and Train ---\n",
    "print(\"\\n--- Preparing Data and Starting Training ---\")\n",
    "\n",
    "# Define training parameters\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 16\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# Create validation set\n",
    "X_train_final, X_val, y_train_final, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=0.1, random_state=RANDOM_STATE, stratify=y_train\n",
    ")\n",
    "\n",
    "# Define custom callback for clean, single-line progress\n",
    "class TrainingProgressCallback(Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        acc = logs.get('accuracy', 0); val_acc = logs.get('val_accuracy', 0)\n",
    "        loss = logs.get('loss', 0); val_loss = logs.get('val_loss', 0)\n",
    "        acc_bar = '█' * int(acc * 20) + '·' * (20 - int(acc * 20))\n",
    "        val_acc_bar = '█' * int(val_acc * 20) + '·' * (20 - int(val_acc * 20))\n",
    "        print(f\"\\rEpoch {epoch+1:02d}/{EPOCHS} | Loss: {loss:.4f} | Acc: {acc:.2%} [{acc_bar}] | Val_Loss: {val_loss:.4f} | Val_Acc: {val_acc:.2%} [{val_acc_bar}]\", end='')\n",
    "\n",
    "# Define early stopping to prevent overfitting\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=3, verbose=1, restore_best_weights=True)\n",
    "\n",
    "# Start training\n",
    "history = model.fit(\n",
    "    X_train_final, y_train_final,\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_data=(X_val, y_val),\n",
    "    verbose=0,\n",
    "    callbacks=[early_stopping, TrainingProgressCallback()]\n",
    ")\n",
    "print(\"\\n\\n--- Training complete. ---\")\n",
    "\n",
    "\n",
    "# --- PART 3: Save the Model ---\n",
    "MODEL_PATH = MODELS_DIR / \"its_genus_classifier.keras\"\n",
    "print(f\"\\nSaving trained model to: {MODEL_PATH}\")\n",
    "try:\n",
    "    model.save(MODEL_PATH)\n",
    "    print(\"  - Model saved successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"[ERROR] Could not save the model: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabdbde0-e2ba-4d20-ab92-97c7f84e089d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
