# =============================================================================
# ATLAS - EXPLORER PIPELINE - SCRIPT 2: CLUSTER SEQUENCES
# =============================================================================
# This script takes the numerical sequence vectors generated by the previous
# script, applies the HDBSCAN algorithm to find clusters, and saves the
# results to a CSV file.
#
# WORKFLOW:
# 1.  Loads the sequence vectors (.npy) and their corresponding IDs (.npy).
# 2.  Instantiates and runs the HDBSCAN clusterer on the vector matrix.
# 3.  Combines the sequence IDs with the resulting cluster labels.
# 4.  Saves this final mapping to a human-readable CSV file, which will be
#     the input for the final interpretation script.
# =============================================================================

# --- Imports ---
import numpy as np
import pandas as pd
import hdbscan
from pathlib import Path
import argparse

# --- Configuration ---
try:
    project_root = Path(__file__).parent.parent.parent
except NameError:
    project_root = Path.cwd().parent if Path.cwd().name == 'notebooks' else Path.cwd()

PROCESSED_DATA_DIR = project_root / "data" / "processed"

# =============================================================================
# --- Main Script Execution ---
# =============================================================================
if __name__ == "__main__":
    # --- Command Line Argument Parsing ---
    parser = argparse.ArgumentParser(description="Cluster sequence vectors using HDBSCAN.")
    parser.add_argument(
        '--vectors_path', type=Path,
        default=PROCESSED_DATA_DIR / "explorer_sequence_vectors.npy",
        help="Path to the input sequence vectors .npy file."
    )
    parser.add_argument(
        '--ids_path', type=Path,
        default=PROCESSED_DATA_DIR / "explorer_sequence_ids.npy",
        help="Path to the corresponding sequence IDs .npy file."
    )
    args = parser.parse_args()
    VECTORS_INPUT_PATH = args.vectors_path
    IDS_INPUT_PATH = args.ids_path

    # --- 1. Load Data ---
    print("--- Step 1: Loading Processed Vector Data ---")
    if not VECTORS_INPUT_PATH.exists() or not IDS_INPUT_PATH.exists():
        print(f"[ERROR] Input files not found. Please run the vectorization script first.")
        exit()
        
    sequence_vectors = np.load(VECTORS_INPUT_PATH)
    sequence_ids = np.load(IDS_INPUT_PATH)
    print(f"  - Loaded {sequence_vectors.shape[0]} sequence vectors.")

    # --- 2. Perform HDBSCAN Clustering ---
    print("\n--- Step 2: Performing HDBSCAN Clustering ---")
    clusterer = hdbscan.HDBSCAN(
        min_cluster_size=5,
        min_samples=1,
        metric='euclidean',
        cluster_selection_method='eom'
    )
    cluster_labels = clusterer.fit_predict(sequence_vectors)
    print("  - Clustering complete.")

    # --- 3. Analyze and Report Results ---
    num_clusters = len(np.unique(cluster_labels)) - 1
    num_noise_points = np.sum(cluster_labels == -1)
    print("\n--- Clustering Summary ---")
    print(f"  - Discovered {num_clusters} new clusters.")
    print(f"  - Labeled {num_noise_points} sequences as noise.")
    
    # --- 4. Save Results to CSV ---
    df_results = pd.DataFrame({
        'sequence_id': sequence_ids,
        'cluster_label': cluster_labels
    })
    
    RESULTS_OUTPUT_PATH = PROCESSED_DATA_DIR / "explorer_cluster_results.csv"
    df_results.to_csv(RESULTS_OUTPUT_PATH, index=False)
    print(f"\n--- Step 3: Saving Results ---")
    print(f"  - Results saved successfully to: {RESULTS_OUTPUT_PATH}")

    # --- Final ASCII Art Confirmation ---
    print("\n" + "="*50)
    print("      EXPLORER CLUSTERING SCRIPT COMPLETE")
    print("="*50 + "\n")
